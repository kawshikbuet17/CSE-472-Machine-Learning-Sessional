{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Load Data Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LoadData import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data and Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_images.shape =  (1000, 28, 28, 1)\n",
      "train_labels.shape =  (1000,)\n",
      "train_images[0].shape =  (28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# load images\n",
    "train_images, train_labels = load_data('training-a', 'training-a.csv')\n",
    "train_images, train_labels = preprocess_data(train_images, train_labels)\n",
    "\n",
    "# print shapes\n",
    "print(\"train_images.shape = \", train_images.shape)\n",
    "print(\"train_labels.shape = \", train_labels.shape)\n",
    "print(\"train_images[0].shape = \", train_images[0].shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into train and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# suffle data\n",
    "s = np.arange(train_images.shape[0])\n",
    "np.random.shuffle(s)\n",
    "train_images = train_images[s]\n",
    "train_labels = train_labels[s]\n",
    "\n",
    "# split data into train and validation\n",
    "train_ratio = 0.8\n",
    "X_train = train_images[:int(train_ratio*len(train_images))]\n",
    "y_train = train_labels[:int(train_ratio*len(train_labels))]\n",
    "X_val = train_images[int(train_ratio*len(train_images)):]\n",
    "y_val = train_labels[int(train_ratio*len(train_labels)):]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ConvolutionLayer import ConvolutionLayer\n",
    "from ReLULayer import ReLULayer\n",
    "from MaxPoolingLayer import MaxPoolingLayer\n",
    "from FlattenLayer import FlattenLayer\n",
    "from FullyConnectedLayer import FullyConnectedLayer\n",
    "from SoftmaxLayer import SoftmaxLayer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Model Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Model import Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use lenet-5 model\n",
    "model = Model(10)\n",
    "model.add(ConvolutionLayer(6, 5, 1, 1))\n",
    "model.add(ReLULayer())\n",
    "model.add(MaxPoolingLayer(pool_size=2, stride=2))\n",
    "model.add(ConvolutionLayer(16, 5, 1, 1))\n",
    "model.add(ReLULayer())\n",
    "model.add(MaxPoolingLayer(pool_size=2, stride=2))\n",
    "model.add(FlattenLayer())\n",
    "model.add(FullyConnectedLayer(output_size=120))\n",
    "model.add(ReLULayer())\n",
    "model.add(FullyConnectedLayer(output_size=84))\n",
    "model.add(ReLULayer())\n",
    "model.add(FullyConnectedLayer(output_size=10))\n",
    "model.add(SoftmaxLayer())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0\n",
      "y_pred (first 10)\t:  [4 2 1 7 8 8 4 4 4 5]\n",
      "y_real (first 10)\t:  [5 2 2 8 1 8 5 5 5 5]\n",
      "accuracy:  0.21\n",
      "epoch:  1\n",
      "y_pred (first 10)\t:  [4 2 1 0 1 3 6 4 4 4]\n",
      "y_real (first 10)\t:  [5 2 2 8 1 8 5 5 5 5]\n",
      "accuracy:  0.265\n",
      "epoch:  2\n",
      "y_pred (first 10)\t:  [4 0 1 0 0 6 5 8 5 4]\n",
      "y_real (first 10)\t:  [5 2 2 8 1 8 5 5 5 5]\n",
      "accuracy:  0.355\n",
      "epoch:  3\n",
      "y_pred (first 10)\t:  [4 0 1 0 2 8 4 8 5 5]\n",
      "y_real (first 10)\t:  [5 2 2 8 1 8 5 5 5 5]\n",
      "accuracy:  0.425\n",
      "epoch:  4\n",
      "y_pred (first 10)\t:  [4 0 1 0 1 3 6 4 5 5]\n",
      "y_real (first 10)\t:  [5 2 2 8 1 8 5 5 5 5]\n",
      "accuracy:  0.445\n",
      "epoch:  5\n",
      "y_pred (first 10)\t:  [4 0 1 0 1 3 4 8 5 5]\n",
      "y_real (first 10)\t:  [5 2 2 8 1 8 5 5 5 5]\n",
      "accuracy:  0.455\n",
      "epoch:  6\n",
      "y_pred (first 10)\t:  [4 0 9 0 2 3 6 4 5 4]\n",
      "y_real (first 10)\t:  [5 2 2 8 1 8 5 5 5 5]\n",
      "accuracy:  0.45\n",
      "epoch:  7\n",
      "y_pred (first 10)\t:  [4 0 1 0 0 8 6 6 5 4]\n",
      "y_real (first 10)\t:  [5 2 2 8 1 8 5 5 5 5]\n",
      "accuracy:  0.52\n",
      "epoch:  8\n",
      "y_pred (first 10)\t:  [4 9 1 0 9 6 5 6 5 5]\n",
      "y_real (first 10)\t:  [5 2 2 8 1 8 5 5 5 5]\n",
      "accuracy:  0.48\n",
      "epoch:  9\n",
      "y_pred (first 10)\t:  [4 0 1 0 2 8 5 8 5 4]\n",
      "y_real (first 10)\t:  [5 2 2 8 1 8 5 5 5 5]\n",
      "accuracy:  0.525\n",
      "epoch:  10\n",
      "y_pred (first 10)\t:  [4 0 1 0 2 8 5 8 5 4]\n",
      "y_real (first 10)\t:  [5 2 2 8 1 8 5 5 5 5]\n",
      "accuracy:  0.54\n",
      "epoch:  11\n",
      "y_pred (first 10)\t:  [4 0 9 8 9 8 6 6 5 4]\n",
      "y_real (first 10)\t:  [5 2 2 8 1 8 5 5 5 5]\n",
      "accuracy:  0.515\n",
      "epoch:  12\n",
      "y_pred (first 10)\t:  [4 0 1 8 9 8 4 6 5 4]\n",
      "y_real (first 10)\t:  [5 2 2 8 1 8 5 5 5 5]\n",
      "accuracy:  0.495\n",
      "epoch:  13\n",
      "y_pred (first 10)\t:  [4 8 1 8 9 8 5 6 5 4]\n",
      "y_real (first 10)\t:  [5 2 2 8 1 8 5 5 5 5]\n",
      "accuracy:  0.54\n",
      "epoch:  14\n",
      "y_pred (first 10)\t:  [4 0 1 8 8 8 5 6 5 4]\n",
      "y_real (first 10)\t:  [5 2 2 8 1 8 5 5 5 5]\n",
      "accuracy:  0.575\n",
      "epoch:  15\n",
      "y_pred (first 10)\t:  [5 0 1 8 0 3 5 6 5 4]\n",
      "y_real (first 10)\t:  [5 2 2 8 1 8 5 5 5 5]\n",
      "accuracy:  0.57\n",
      "epoch:  16\n",
      "y_pred (first 10)\t:  [5 8 8 8 8 8 5 6 5 4]\n",
      "y_real (first 10)\t:  [5 2 2 8 1 8 5 5 5 5]\n",
      "accuracy:  0.535\n",
      "epoch:  17\n",
      "y_pred (first 10)\t:  [5 8 1 8 9 8 5 5 5 5]\n",
      "y_real (first 10)\t:  [5 2 2 8 1 8 5 5 5 5]\n",
      "accuracy:  0.565\n",
      "epoch:  18\n",
      "y_pred (first 10)\t:  [6 0 8 8 8 8 5 6 5 5]\n",
      "y_real (first 10)\t:  [5 2 2 8 1 8 5 5 5 5]\n",
      "accuracy:  0.565\n",
      "epoch:  19\n",
      "y_pred (first 10)\t:  [4 0 8 8 1 8 5 6 5 5]\n",
      "y_real (first 10)\t:  [5 2 2 8 1 8 5 5 5 5]\n",
      "accuracy:  0.605\n",
      "epoch:  20\n",
      "y_pred (first 10)\t:  [6 0 8 8 1 5 5 6 5 5]\n",
      "y_real (first 10)\t:  [5 2 2 8 1 8 5 5 5 5]\n",
      "accuracy:  0.57\n",
      "epoch:  21\n",
      "y_pred (first 10)\t:  [6 9 2 8 9 6 5 6 5 5]\n",
      "y_real (first 10)\t:  [5 2 2 8 1 8 5 5 5 5]\n",
      "accuracy:  0.555\n",
      "epoch:  22\n",
      "y_pred (first 10)\t:  [4 8 8 8 8 8 5 5 5 5]\n",
      "y_real (first 10)\t:  [5 2 2 8 1 8 5 5 5 5]\n",
      "accuracy:  0.56\n",
      "epoch:  23\n",
      "y_pred (first 10)\t:  [6 7 8 8 8 4 6 6 5 6]\n",
      "y_real (first 10)\t:  [5 2 2 8 1 8 5 5 5 5]\n",
      "accuracy:  0.49\n",
      "epoch:  24\n",
      "y_pred (first 10)\t:  [4 0 2 8 8 4 6 6 5 4]\n",
      "y_real (first 10)\t:  [5 2 2 8 1 8 5 5 5 5]\n",
      "accuracy:  0.555\n",
      "epoch:  25\n",
      "y_pred (first 10)\t:  [4 0 8 8 8 4 5 6 5 5]\n",
      "y_real (first 10)\t:  [5 2 2 8 1 8 5 5 5 5]\n",
      "accuracy:  0.6\n",
      "epoch:  26\n",
      "y_pred (first 10)\t:  [4 0 8 8 8 6 5 0 5 5]\n",
      "y_real (first 10)\t:  [5 2 2 8 1 8 5 5 5 5]\n",
      "accuracy:  0.64\n",
      "epoch:  27\n",
      "y_pred (first 10)\t:  [4 0 8 8 8 8 6 6 5 5]\n",
      "y_real (first 10)\t:  [5 2 2 8 1 8 5 5 5 5]\n",
      "accuracy:  0.585\n",
      "epoch:  28\n",
      "y_pred (first 10)\t:  [5 0 9 8 8 8 5 6 5 5]\n",
      "y_real (first 10)\t:  [5 2 2 8 1 8 5 5 5 5]\n",
      "accuracy:  0.6\n",
      "epoch:  29\n",
      "y_pred (first 10)\t:  [4 9 8 8 8 8 5 0 5 4]\n",
      "y_real (first 10)\t:  [5 2 2 8 1 8 5 5 5 5]\n",
      "accuracy:  0.59\n",
      "epoch:  30\n",
      "y_pred (first 10)\t:  [4 0 9 8 8 8 5 0 5 4]\n",
      "y_real (first 10)\t:  [5 2 2 8 1 8 5 5 5 5]\n",
      "accuracy:  0.555\n",
      "epoch:  31\n",
      "y_pred (first 10)\t:  [4 0 8 8 8 8 5 7 5 4]\n",
      "y_real (first 10)\t:  [5 2 2 8 1 8 5 5 5 5]\n",
      "accuracy:  0.525\n",
      "epoch:  32\n",
      "y_pred (first 10)\t:  [4 0 8 8 8 6 5 5 5 5]\n",
      "y_real (first 10)\t:  [5 2 2 8 1 8 5 5 5 5]\n",
      "accuracy:  0.575\n",
      "epoch:  33\n",
      "y_pred (first 10)\t:  [4 0 2 8 8 3 5 6 5 5]\n",
      "y_real (first 10)\t:  [5 2 2 8 1 8 5 5 5 5]\n",
      "accuracy:  0.58\n",
      "epoch:  34\n",
      "y_pred (first 10)\t:  [4 0 2 8 8 3 4 6 5 5]\n",
      "y_real (first 10)\t:  [5 2 2 8 1 8 5 5 5 5]\n",
      "accuracy:  0.55\n",
      "epoch:  35\n",
      "y_pred (first 10)\t:  [4 0 2 8 8 8 6 6 4 6]\n",
      "y_real (first 10)\t:  [5 2 2 8 1 8 5 5 5 5]\n",
      "accuracy:  0.525\n",
      "epoch:  36\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [8], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# train\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m model\u001b[39m.\u001b[39;49mtrain(X_train\u001b[39m=\u001b[39;49mX_train, y_train\u001b[39m=\u001b[39;49my_train, X_val\u001b[39m=\u001b[39;49mX_val, y_val\u001b[39m=\u001b[39;49my_val, learning_rate\u001b[39m=\u001b[39;49m\u001b[39m0.00001\u001b[39;49m, epochs\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m64\u001b[39;49m)\n",
      "File \u001b[1;32md:\\Coding\\L4-T2\\CSE-472-Machine-Learning-Sessional\\Offline-04-Convolutional-Neural-Network\\Code\\Model.py:56\u001b[0m, in \u001b[0;36mModel.train\u001b[1;34m(self, X_train, y_train, X_val, y_val, learning_rate, epochs, batch_size)\u001b[0m\n\u001b[0;32m     54\u001b[0m     grad \u001b[39m=\u001b[39m y_pred \u001b[39m-\u001b[39m y_batch_one_hot\n\u001b[0;32m     55\u001b[0m     \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m \u001b[39mreversed\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers):\n\u001b[1;32m---> 56\u001b[0m         grad \u001b[39m=\u001b[39m layer\u001b[39m.\u001b[39;49mbackprop(grad, learning_rate)\n\u001b[0;32m     58\u001b[0m \u001b[39m# evaluate model\u001b[39;00m\n\u001b[0;32m     59\u001b[0m accuracy \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mevaluate(X_val, y_val)\n",
      "File \u001b[1;32md:\\Coding\\L4-T2\\CSE-472-Machine-Learning-Sessional\\Offline-04-Convolutional-Neural-Network\\Code\\MaxPoolingLayer.py:77\u001b[0m, in \u001b[0;36mMaxPoolingLayer.backprop\u001b[1;34m(self, output_error, learning_rate)\u001b[0m\n\u001b[0;32m     74\u001b[0m                 max_value \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmax(current_region)\n\u001b[0;32m     75\u001b[0m                 max_index \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margmax(current_region)\n\u001b[1;32m---> 77\u001b[0m                 k, l \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49munravel_index(max_index, pool_size)\n\u001b[0;32m     79\u001b[0m                 input_data_gradient[b, i\u001b[39m+\u001b[39mk, j\u001b[39m+\u001b[39ml, m] \u001b[39m=\u001b[39m output_error[b, \u001b[39mint\u001b[39m(i\u001b[39m/\u001b[39mstride), \u001b[39mint\u001b[39m(j\u001b[39m/\u001b[39mstride), m]\n\u001b[0;32m     82\u001b[0m \u001b[39mreturn\u001b[39;00m input_data_gradient\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36munravel_index\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train\n",
    "model.train(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, learning_rate=0.00001, epochs=100, batch_size=64)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model using pickle\n",
    "import pickle\n",
    "with open('model.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "# Load the model using pickle\n",
    "with open('model.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performace Metrics and Confusion Matrix"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load test images\n",
    "test_images, test_labels = load_data('training-d', 'training-d.csv')\n",
    "test_images, test_labels = preprocess_data(test_images, test_labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Matrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# performance metrics and confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# predict   \n",
    "y_pred = model.predict(test_images)\n",
    "\n",
    "# print performance metrics\n",
    "print(\"Accuracy: \", accuracy_score(test_labels, y_pred))\n",
    "print(\"Confusion Matrix: \", confusion_matrix(test_labels, y_pred))\n",
    "\n",
    "# print classification report\n",
    "print(\"Classification Report: \", classification_report(test_labels, y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confustion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot confusion matrix using seaborn\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cm = confusion_matrix(test_labels, y_pred)\n",
    "plt.figure(figsize=(10, 10))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "plt.title(\"Confusion matrix\")\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "b33069848e313ad49d053c5e2afad7bf1a5908034c1949d44822ff536d0b5b4f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
